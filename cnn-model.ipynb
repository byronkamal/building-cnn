{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib (from -r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/e9/69/f5e05f578585ed9935247be3788b374f90701296a70c8871bcd6d21edb00/matplotlib-3.0.3-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting numpy (from -r requirements.txt (line 2))\n",
      "  Using cached https://files.pythonhosted.org/packages/c1/e2/4db8df8f6cddc98e7d7c537245ef2f4e41a1ed17bf0c3177ab3cc6beac7f/numpy-1.16.3-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting tensorflow (from -r requirements.txt (line 3))\n",
      "  Using cached https://files.pythonhosted.org/packages/77/63/a9fa76de8dffe7455304c4ed635be4aa9c0bacef6e0633d87d5f54530c5c/tensorflow-1.13.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting keras (from -r requirements.txt (line 4))\n",
      "  Using cached https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl\n",
      "Collecting pandas (from -r requirements.txt (line 5))\n",
      "  Using cached https://files.pythonhosted.org/packages/19/74/e50234bc82c553fecdbd566d8650801e3fe2d6d8c8d940638e3d8a7c5522/pandas-0.24.2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting Pillow (from -r requirements.txt (line 6))\n",
      "  Using cached https://files.pythonhosted.org/packages/d2/c2/f84b1e57416755e967236468dcfb0fad7fd911f707185efc4ba8834a1a94/Pillow-6.0.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: python-dateutil>=2.1 in ./.env/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 1)) (2.8.0)\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/f8/a1/5742b56282449b1c0968197f63eae486eca2c35dcd334bab75ad524e0de1/kiwisolver-1.1.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/dd/d9/3ec19e966301a6e25769976999bd7bbe552016f0d32b577dc9d63d2e0c49/pyparsing-2.4.0-py2.py3-none-any.whl\n",
      "Collecting cycler>=0.10 (from matplotlib->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting tensorboard<1.14.0,>=1.13.0 (from tensorflow->-r requirements.txt (line 3))\n",
      "  Using cached https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl\n",
      "Requirement already satisfied: wheel>=0.26 in ./.env/lib/python3.6/site-packages (from tensorflow->-r requirements.txt (line 3)) (0.33.4)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow->-r requirements.txt (line 3))\n",
      "Collecting keras-applications>=1.0.6 (from tensorflow->-r requirements.txt (line 3))\n",
      "  Using cached https://files.pythonhosted.org/packages/90/85/64c82949765cfb246bbdaf5aca2d55f400f792655927a017710a78445def/Keras_Applications-1.0.7-py2.py3-none-any.whl\n",
      "Collecting astor>=0.6.0 (from tensorflow->-r requirements.txt (line 3))\n",
      "  Using cached https://files.pythonhosted.org/packages/35/6b/11530768cac581a12952a2aad00e1526b89d242d0b9f59534ef6e6a1752f/astor-0.7.1-py2.py3-none-any.whl\n",
      "Collecting grpcio>=1.8.6 (from tensorflow->-r requirements.txt (line 3))\n",
      "  Using cached https://files.pythonhosted.org/packages/0a/9d/8bd5d0e516b196f59f1c4439b424b8d4fa62d492a4b531aae322d2d82a7b/grpcio-1.20.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting protobuf>=3.6.1 (from tensorflow->-r requirements.txt (line 3))\n",
      "  Using cached https://files.pythonhosted.org/packages/5a/aa/a858df367b464f5e9452e1c538aa47754d467023850c00b000287750fa77/protobuf-3.7.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0 (from tensorflow->-r requirements.txt (line 3))\n",
      "  Using cached https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl\n",
      "Collecting keras-preprocessing>=1.0.5 (from tensorflow->-r requirements.txt (line 3))\n",
      "  Using cached https://files.pythonhosted.org/packages/c0/bf/0315ef6a9fd3fc2346e85b0ff1f5f83ca17073f2c31ac719ab2e4da0d4a3/Keras_Preprocessing-1.0.9-py2.py3-none-any.whl\n",
      "Collecting gast>=0.2.0 (from tensorflow->-r requirements.txt (line 3))\n",
      "Requirement already satisfied: six>=1.10.0 in ./.env/lib/python3.6/site-packages (from tensorflow->-r requirements.txt (line 3)) (1.12.0)\n",
      "Collecting absl-py>=0.1.6 (from tensorflow->-r requirements.txt (line 3))\n",
      "Collecting scipy>=0.14 (from keras->-r requirements.txt (line 4))\n",
      "  Using cached https://files.pythonhosted.org/packages/7f/5f/c48860704092933bf1c4c1574a8de1ffd16bf4fde8bab190d747598844b2/scipy-1.2.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting pyyaml (from keras->-r requirements.txt (line 4))\n",
      "Collecting h5py (from keras->-r requirements.txt (line 4))\n",
      "  Using cached https://files.pythonhosted.org/packages/30/99/d7d4fbf2d02bb30fb76179911a250074b55b852d34e98dd452a9f394ac06/h5py-2.9.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting pytz>=2011k (from pandas->-r requirements.txt (line 5))\n",
      "  Using cached https://files.pythonhosted.org/packages/3d/73/fe30c2daaaa0713420d0382b16fbb761409f532c56bdcc514bf7b6262bb6/pytz-2019.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: setuptools in ./.env/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib->-r requirements.txt (line 1)) (41.0.1)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.14.0,>=1.13.0->tensorflow->-r requirements.txt (line 3))\n",
      "  Using cached https://files.pythonhosted.org/packages/f5/e4/d8c18f2555add57ff21bf25af36d827145896a07607486cc79a2aea641af/Markdown-3.1-py2.py3-none-any.whl\n",
      "Collecting werkzeug>=0.11.15 (from tensorboard<1.14.0,>=1.13.0->tensorflow->-r requirements.txt (line 3))\n",
      "  Using cached https://files.pythonhosted.org/packages/18/79/84f02539cc181cdbf5ff5a41b9f52cae870b6f632767e43ba6ac70132e92/Werkzeug-0.15.2-py2.py3-none-any.whl\n",
      "Collecting mock>=2.0.0 (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow->-r requirements.txt (line 3))\n",
      "  Using cached https://files.pythonhosted.org/packages/05/d2/f94e68be6b17f46d2c353564da56e6fb89ef09faeeff3313a046cb810ca9/mock-3.0.5-py2.py3-none-any.whl\n",
      "Installing collected packages: kiwisolver, pyparsing, numpy, cycler, matplotlib, grpcio, absl-py, markdown, protobuf, werkzeug, tensorboard, termcolor, h5py, keras-applications, astor, mock, tensorflow-estimator, keras-preprocessing, gast, tensorflow, scipy, pyyaml, keras, pytz, pandas, Pillow\n",
      "Successfully installed Pillow-6.0.0 absl-py-0.7.1 astor-0.7.1 cycler-0.10.0 gast-0.2.2 grpcio-1.20.1 h5py-2.9.0 keras-2.2.4 keras-applications-1.0.7 keras-preprocessing-1.0.9 kiwisolver-1.1.0 markdown-3.1 matplotlib-3.0.3 mock-3.0.5 numpy-1.16.3 pandas-0.24.2 protobuf-3.7.1 pyparsing-2.4.0 pytz-2019.1 pyyaml-5.1 scipy-1.2.1 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0 termcolor-1.1.0 werkzeug-0.15.2\n"
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D, BatchNormalization\n",
    "\n",
    "# Create model\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional Layer\n",
    "model.add(Conv2D(32, (3,3), input_shape=(64,64,3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale= 1./255,\n",
    "                               zoom_range=0.2,\n",
    "                               rotation_range=15,\n",
    "                               horizontal_flip=True,\n",
    "                               height_shift_range=0.5)\n",
    "\n",
    "test_gen = ImageDataGenerator(rescale= 1./255)\n",
    "\n",
    "train_data = train_gen.flow_from_directory('dataset/training_set', target_size=(64,64), batch_size=64, class_mode='binary')\n",
    "test_data = test_gen.flow_from_directory('dataset/test_set', target_size=(64,64), batch_size=64, class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "4000/4000 [==============================] - 5024s 1s/step - loss: 0.4288 - acc: 0.7942 - val_loss: 0.4122 - val_acc: 0.8066\n",
      "Epoch 2/12\n",
      "4000/4000 [==============================] - 4948s 1s/step - loss: 0.2855 - acc: 0.8753 - val_loss: 0.3920 - val_acc: 0.8546\n",
      "Epoch 3/12\n",
      "4000/4000 [==============================] - 4907s 1s/step - loss: 0.2287 - acc: 0.9029 - val_loss: 0.3269 - val_acc: 0.8686\n",
      "Epoch 4/12\n",
      "4000/4000 [==============================] - 4886s 1s/step - loss: 0.1913 - acc: 0.9202 - val_loss: 0.3467 - val_acc: 0.8639\n",
      "Epoch 5/12\n",
      "4000/4000 [==============================] - 4871s 1s/step - loss: 0.1656 - acc: 0.9323 - val_loss: 0.3077 - val_acc: 0.8944\n",
      "Epoch 6/12\n",
      "4000/4000 [==============================] - 4847s 1s/step - loss: 0.1457 - acc: 0.9413 - val_loss: 0.3361 - val_acc: 0.8948\n",
      "Epoch 7/12\n",
      "4000/4000 [==============================] - 4840s 1s/step - loss: 0.1330 - acc: 0.9465 - val_loss: 0.3621 - val_acc: 0.8832\n",
      "Epoch 8/12\n",
      "4000/4000 [==============================] - 4831s 1s/step - loss: 0.1207 - acc: 0.9525 - val_loss: 0.3007 - val_acc: 0.9075\n",
      "Epoch 9/12\n",
      "4000/4000 [==============================] - 4865s 1s/step - loss: 0.1117 - acc: 0.9564 - val_loss: 0.3539 - val_acc: 0.8981\n",
      "Epoch 10/12\n",
      "4000/4000 [==============================] - 5262s 1s/step - loss: 0.1048 - acc: 0.9597 - val_loss: 0.3740 - val_acc: 0.8901\n",
      "Epoch 11/12\n",
      "4000/4000 [==============================] - 5690s 1s/step - loss: 0.0971 - acc: 0.9626 - val_loss: 0.5718 - val_acc: 0.8520\n",
      "Epoch 12/12\n",
      "4000/4000 [==============================] - 6620s 2s/step - loss: 0.0921 - acc: 0.9644 - val_loss: 0.3316 - val_acc: 0.8966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1fc4c3dc18>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "model.fit_generator(train_data, steps_per_epoch=4000, epochs=12, validation_data=test_data, validation_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('second_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
