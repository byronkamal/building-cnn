{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Keras libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/lib/python3.7/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Building the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Conv2D(32, (4, 4), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 32, activation = 'relu'))\n",
    "\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "classifier.add(Dropout(rate=0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Fitting the CNN to the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/15\n",
      "8000/8000 [==============================] - 1095s 137ms/step - loss: 2.0137 - acc: 0.7057 - val_loss: 0.5481 - val_acc: 0.7160\n",
      "Epoch 2/15\n",
      "8000/8000 [==============================] - 1078s 135ms/step - loss: 1.8967 - acc: 0.7879 - val_loss: 0.5582 - val_acc: 0.7613\n",
      "Epoch 3/15\n",
      "8000/8000 [==============================] - 1080s 135ms/step - loss: 1.8520 - acc: 0.8150 - val_loss: 0.6304 - val_acc: 0.7594\n",
      "Epoch 4/15\n",
      "8000/8000 [==============================] - 1077s 135ms/step - loss: 1.7629 - acc: 0.8474 - val_loss: 0.7843 - val_acc: 0.7622\n",
      "Epoch 5/15\n",
      "8000/8000 [==============================] - 1079s 135ms/step - loss: 1.7183 - acc: 0.8654 - val_loss: 0.9013 - val_acc: 0.7628\n",
      "Epoch 6/15\n",
      "8000/8000 [==============================] - 1080s 135ms/step - loss: 1.7139 - acc: 0.8729 - val_loss: 0.9305 - val_acc: 0.7551\n",
      "Epoch 7/15\n",
      "8000/8000 [==============================] - 1079s 135ms/step - loss: 1.7061 - acc: 0.8752 - val_loss: 0.8144 - val_acc: 0.7524\n",
      "Epoch 8/15\n",
      "8000/8000 [==============================] - 1076s 134ms/step - loss: 1.6731 - acc: 0.8857 - val_loss: 0.9128 - val_acc: 0.7671\n",
      "Epoch 9/15\n",
      "8000/8000 [==============================] - 1082s 135ms/step - loss: 1.6410 - acc: 0.8887 - val_loss: 0.9666 - val_acc: 0.7638\n",
      "Epoch 10/15\n",
      "8000/8000 [==============================] - 1078s 135ms/step - loss: 1.6516 - acc: 0.8888 - val_loss: 1.0403 - val_acc: 0.7729\n",
      "Epoch 11/15\n",
      "8000/8000 [==============================] - 1080s 135ms/step - loss: 1.6507 - acc: 0.8908 - val_loss: 1.0207 - val_acc: 0.7605\n",
      "Epoch 12/15\n",
      "8000/8000 [==============================] - 1081s 135ms/step - loss: 1.6488 - acc: 0.8902 - val_loss: 1.1316 - val_acc: 0.7575\n",
      "Epoch 13/15\n",
      "8000/8000 [==============================] - 1083s 135ms/step - loss: 1.6233 - acc: 0.8954 - val_loss: 1.0460 - val_acc: 0.7497\n",
      "Epoch 14/15\n",
      "8000/8000 [==============================] - 1083s 135ms/step - loss: 1.6286 - acc: 0.8946 - val_loss: 1.1701 - val_acc: 0.7514\n",
      "Epoch 15/15\n",
      "8000/8000 [==============================] - 1080s 135ms/step - loss: 1.6417 - acc: 0.8927 - val_loss: 0.8325 - val_acc: 0.7474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa67a98aeb8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "\n",
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 8000,\n",
    "                         epochs = 15,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "\n",
    "if result[0][0] == 1:\n",
    "    prediction ='dog'\n",
    "else:\n",
    "    prediction = 'cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first single prediciton is  dog\n"
     ]
    }
   ],
   "source": [
    "print(\"first single prediciton is \", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
